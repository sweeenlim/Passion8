{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DB Initialisation Script\n",
    "\n",
    "This notebook can be used for setting up local Postgres database called 'dsa3101' and for querying the database\n",
    "\n",
    "To get started, please change the env variables in the next code chunk and simply 'Run All' to load the database.\n",
    "\n",
    "Ensure that your .venv is activated in this Jupyter environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOCHANGE\n",
    "\n",
    "YOUR_POSTGRES_PASSWORD = 'example123' \n",
    "YOUR_POSTGRES_PORT_NO = 5432 \n",
    "\n",
    "# Default if you have cloned from repo-main \n",
    "path_to_products_csv = 'products.csv'\n",
    "path_to_ratings_csv = 'ratings.csv'\n",
    "path_to_dailysales_csv = 'daily_sales.csv'\n",
    "path_to_users_csv = 'users.csv'\n",
    "path_to_user_behaviour_csv = 'user_behaviour.csv'\n",
    "host = 'localhost'\n",
    "database = 'dsa3101' # default db name\n",
    "user = 'postgres'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install ipython-sql\n",
    "!pip3 install sqlalchemy\n",
    "!pip3 install psycopg2-binary\n",
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, Table, Column, MetaData, String, Numeric, Float, Integer, ForeignKey, Date, ForeignKeyConstraint,DateTime\n",
    "import pandas as pd\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Connect to the default database (postgres) to check/create the 'dsa3101' database\n",
    "try:\n",
    "    # Connect to the 'postgres' database (default)\n",
    "    conn = psycopg2.connect(\n",
    "        host=host,\n",
    "        user=user,\n",
    "        password=YOUR_POSTGRES_PASSWORD,\n",
    "        port=YOUR_POSTGRES_PORT_NO,\n",
    "        database='postgres'  # Connect to 'postgres' instead of 'dsa3101' initially\n",
    "    )\n",
    "    conn.autocommit = True  # Enable autocommit so that CREATE DATABASE works\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Check if the 'dsa3101' database exists\n",
    "    cursor.execute(f\"SELECT 1 FROM pg_database WHERE datname = '{database}';\")\n",
    "    exists = cursor.fetchone()\n",
    "\n",
    "    # If the database doesn't exist, create it\n",
    "    if not exists:\n",
    "        cursor.execute(f'CREATE DATABASE {database};')\n",
    "        print(f\"Database '{database}' has been created.\")\n",
    "    else:\n",
    "        print(f\"Database '{database}' already exists.\")\n",
    "    \n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error while creating or checking the database: {e}\")\n",
    "\n",
    "# Step 2: Now connect to the newly created or existing 'dsa3101' database\n",
    "try:\n",
    "    engine = create_engine(f'postgresql://{user}:{YOUR_POSTGRES_PASSWORD}@{host}:{YOUR_POSTGRES_PORT_NO}/{database}')\n",
    "\n",
    "    # Define MetaData for the DB\n",
    "    metadata = MetaData()\n",
    "\n",
    "    # Reflect existing tables from the 'dsa3101' database\n",
    "    metadata.reflect(bind=engine)\n",
    "    \n",
    "    # Drop all tables in the 'dsa3101' database\n",
    "    metadata.drop_all(bind=engine)\n",
    "    print(\"All pre-existing tables have been dropped.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error while reflecting or dropping tables: {e}\")\n",
    "\n",
    "finally:\n",
    "    metadata = MetaData()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading tables into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and Load  table - products\n",
    "\n",
    "\n",
    "products_table = Table('products', metadata,\n",
    "    Column('product_id', String(50), primary_key=True),\n",
    "    Column('product_name', String(500)),\n",
    "    Column('about_product', String),  # Use String for TEXT in SQLAlchemy\n",
    "    Column('category', String(255)),\n",
    "    Column('actual_price', Numeric(10, 2)),\n",
    "    Column('discounted_price', Numeric(10, 2)),\n",
    "    Column('discount_percentage', Numeric(5, 2))\n",
    ")\n",
    "\n",
    "# Create the table in the database if it doesn't exist\n",
    "metadata.create_all(engine)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "products_df = pd.read_csv(path_to_products_csv)\n",
    "\n",
    "# Insert data into the PostgreSQL table\n",
    "products_df.to_sql('products', engine, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and Load table - ratings\n",
    "\n",
    "# Define the 'ratings' table schema\n",
    "ratings_table = Table('ratings', metadata,\n",
    "    Column('product_id', String(50), ForeignKey('products.product_id', ondelete='CASCADE'), primary_key=True),\n",
    "    Column('average_rating', Float),\n",
    "    Column('review_title', String(1000)),\n",
    "    Column('review_content', String),  # Use String for TEXT in SQLAlchemy\n",
    "    Column('rating_count', Integer)\n",
    ")\n",
    "\n",
    "# Create the table in the database if it doesn't exist\n",
    "metadata.create_all(engine)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "ratings_df = pd.read_csv(path_to_ratings_csv)\n",
    "\n",
    "# Insert data into the PostgreSQL table\n",
    "ratings_df.to_sql('ratings', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the 'daily_sales' table schema\n",
    "daily_sales_table = Table('daily_sales', metadata,\n",
    "    Column('transaction_id', Integer, primary_key=True),\n",
    "    Column('date', Date),\n",
    "    Column('product_id', String(50), ForeignKey('products.product_id', ondelete='CASCADE'), nullable=False),\n",
    "    Column('quantity', Integer)\n",
    ")\n",
    "\n",
    "# Create the table in the database if it doesn't exist\n",
    "metadata.create_all(engine)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "daily_sales_df = pd.read_csv(path_to_dailysales_csv)\n",
    "\n",
    "# Convert 'date' column to correct format if necessary\n",
    "daily_sales_df['date'] = pd.to_datetime(daily_sales_df['date'], format='%d/%m/%Y', errors='coerce')\n",
    "\n",
    "# Insert data into the PostgreSQL table\n",
    "daily_sales_df.to_sql('daily_sales', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the 'users' table schema\n",
    "users_table = Table('users', metadata,\n",
    "    Column('user_id', Integer, primary_key=True),\n",
    "    Column('age', Integer),  \n",
    "    Column('gender', String(50))\n",
    ")\n",
    "\n",
    "# Define the 'user_behaviour' table schema\n",
    "user_behaviour_table = Table('user_behaviour', metadata,\n",
    "    Column('user_id', Integer, primary_key=True),\n",
    "    Column('timestamp', DateTime),\n",
    "    Column('purchase_Frequency', String(50)),\n",
    "    Column('purchase_Categories', String(255)),\n",
    "    Column('personalized_Recommendation_Success', String(50)),\n",
    "    Column('browsing_Frequency', String(50)),\n",
    "    Column('product_Search_Method', String(50)),\n",
    "    Column('search_Result_Exploration', String(50)),\n",
    "    Column('customer_Reviews_Importance', String(1)),  \n",
    "    Column('add_to_Cart_Browsing', String(50)),\n",
    "    Column('cart_Completion_Frequency', String(50)),\n",
    "    Column('cart_Abandonment_Factors', String(255)),\n",
    "    Column('saveforlater_Frequency', String(50)),\n",
    "    Column('review_Left', String(50)),\n",
    "    Column('review_Reliability', String(50)),\n",
    "    Column('review_Helpfulness', String(50)),\n",
    "    Column('recommendation_Helpfulness', String(50)),\n",
    "    Column('personalized_Recommendation_Frequency', String(1)),\n",
    "    Column('rating_Accuracy', String(1)),  \n",
    "    Column('shopping_Satisfaction', String(1)),  \n",
    "    Column('service_Appreciation', String(255)),\n",
    "    Column('improvement_Areas', String(255)),\n",
    "    ForeignKeyConstraint(['user_id'], ['users.user_id'], ondelete='CASCADE')\n",
    ")\n",
    "\n",
    "# Create the tables in the database if they don't exist\n",
    "metadata.create_all(engine)\n",
    "\n",
    "# Read the CSV files into DataFrames\n",
    "users_df = pd.read_csv(path_to_users_csv)\n",
    "user_behaviour_df = pd.read_csv(path_to_user_behaviour_csv)\n",
    "\n",
    "# Insert data into the PostgreSQL tables\n",
    "users_df.to_sql('users', engine, if_exists='append', index=False)\n",
    "user_behaviour_df.to_sql('user_behaviour', engine, if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
